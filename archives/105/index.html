<!DOCTYPE HTML>
<html lang="zh-CN">
    <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="renderer" content="webkit">
    <meta name="HandheldFriendly" content="true">
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
    <meta name="keywords" content="Maverick,熊猫小A,Galileo,blog" />
    <meta name="generator" content="Maverick 1.1" />
    <meta name="template" content="Galileo" />
    <link rel="alternate" type="application/rss+xml" title="无文字 | 三无计划 &raquo; RSS 2.0" href="/feed/index.xml" />
    <link rel="alternate" type="application/atom+xml" title="无文字 | 三无计划 &raquo; ATOM 1.0" href="/feed/atom/index.xml" />
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/AlanDecode/site-Blog@gh-pages/assets/galileo-47943f640b.css">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/AlanDecode/site-Blog@gh-pages/assets/ExSearch/ExSearch-182e5a8868.css">
    <link href="https://fonts.googleapis.com/css?family=Fira+Code&display=swap" rel="stylesheet">
    <script>
        var ExSearchConfig = {
            root: "",
            api: "https://cdn.jsdelivr.net/gh/AlanDecode/site-Blog@gh-pages/993aa3dcb70943b3e506b13b3d502541.json"
        }
    </script>
    
<title>CUDA 中的数组(Array)与纹理存储(Texture)介绍与使用 - 无文字 | 三无计划</title>
<meta name="author" content="熊猫小A" />
<meta name="description" content="这篇文章主要介绍一种存储器：纹理存储器（Texture Memory），以及如何使用它加速访问线性内存与 CUDA 数组（Array）。" />
<meta property="og:title" content="CUDA 中的数组(Array)与纹理存储(Texture)介绍与使用 - 无文字 | 三无计划" />
<meta property="og:description" content="这篇文章主要介绍一种存储器：纹理存储器（Texture Memory），以及如何使用它加速访问线性内存与 CUDA 数组（Array）。" />
<meta property="og:site_name" content="无文字 | 三无计划" />
<meta property="og:type" content="article" />
<meta property="og:url" content="/archives/105/" />
<meta property="og:image" content="" />
<meta property="article:published_time" content="2018-04-19T10:34:00-00.00" />
<meta name="twitter:title" content="CUDA 中的数组(Array)与纹理存储(Texture)介绍与使用 - 无文字 | 三无计划" />
<meta name="twitter:description" content="这篇文章主要介绍一种存储器：纹理存储器（Texture Memory），以及如何使用它加速访问线性内存与 CUDA 数组（Array）。" />
<meta name="twitter:card" content="summary" />
<meta name="twitter:image" content="" />


    
<meta http-equiv="x-dns-prefetch-control" content="on">
<link rel="dns-prefetch" href="//cdn.jsdelivr.net" />
<link rel="dns-prefetch" href="//blog.imalan.cn" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/AlanDecode/site-Blog@gh-pages/brand_font/embed.css" />
<style>.brand{font-family:FZCuJinLFW,serif;font-weight: normal!important;}</style>
<meta name="apple-mobile-web-app-capable" content="yes">
<meta name="apple-mobile-web-app-status-bar-style" content="black">
<link rel="apple-touch-icon" sizes="180x180" href="https://cdn.jsdelivr.net/gh/AlanDecode/site-Blog@gh-pages/apple-touch-icon.png?v=PY43YeeEKx">
<link rel="icon" type="image/png" sizes="32x32" href="https://cdn.jsdelivr.net/gh/AlanDecode/site-Blog@gh-pages/favicon-32x32.png?v=yyLyaqbyRG">
<link rel="icon" type="image/png" sizes="16x16" href="https://cdn.jsdelivr.net/gh/AlanDecode/site-Blog@gh-pages/favicon-16x16.png?v=yyLyaqbyRG">
<link rel="mask-icon" href="https://cdn.jsdelivr.net/gh/AlanDecode/site-Blog@gh-pages/safari-pinned-tab.svg?v=yyLyaqbyRG" color="#505050">
<link rel="shortcut icon" href="https://cdn.jsdelivr.net/gh/AlanDecode/site-Blog@gh-pages/favicon.ico?v=yyLyaqbyRG">
<meta name="application-name" content="三無計劃">
<meta name="apple-mobile-web-app-title" content="三無計劃">
<meta name="msapplication-TileColor" content="#000000">
<meta name="theme-color" content="#000000">
<meta name="baidu-site-verification" content="9BEwwo6Ibg" />

    </head>
    
    <body>
        
            <div id="bg" style="background-image: url(https://cdn.jsdelivr.net/gh/AlanDecode/site-Blog@gh-pages/bg/The_Great_Wave_off_Kanagawa.jpg)"></div>
        
        <div class="container">
            <header id="ga-header">
                <div first>
                    <aside id="ga-brand">
                        <h1 class="brand"><a class="no-style" href="/">无文字 | 三无计划</a></h1>
                        <p>只坚持一种正义。我的正义。</p>
                    </aside>
                </div>
                <div second id="ga-nav">
                    <nav class="navs">
                        <ul><li><a class="ga-highlight" href="/" target="_self">首页</a></li><span class="separator">·</span><li><a class="ga-highlight" href="/archives/" target="_self">归档</a></li><span class="separator">·</span><li><a class="ga-highlight" href="/links/" target="_self">友链</a></li><span class="separator">·</span><li><a class="ga-highlight" href="/about/" target="_self">关于</a></li><span class="separator">·</span><li><a href="#" target="_self" class="search-form-input ga-highlight">搜索</a></li></ul>
                    </nav>
                </div>
            </header>
            <div class="wrapper">
                
<main>    
    <section class="ga-section ga-content">
        <article class="yue">
            <h1 class="ga-post_title">CUDA 中的数组(Array)与纹理存储(Texture)介绍与使用</h1>
            <span class="ga-post_meta ga-mono">
                <span>熊猫小A</span>
                <time>
                    2018-04-19
                </time>
                
                in <a no-style class="category" href="/category/偶尔Geek/">
                    偶尔Geek
                </a>
                
                
                <span class="leancloud_visitors" 
                    id="/archives/105/" 
                    data-flag-title="CUDA 中的数组(Array)与纹理存储(Texture)介绍与使用"> · <i class="leancloud-visitors-count"></i> Views</span>
                
            </span>
            <div class="ga-content_body">
                <p>CUDA 中有不同的内存类型，包括全局存储（Global Memory）、共享存储（Shared Memory）、常数存储器（Constant Memory）、寄存器（Register）等。这些不同类型的存储器在物理位置、访问效率上各有不同，因此适合不同的应用场景，这里不展开。这篇文章主要介绍一种存储器：纹理存储器（Texture Memory），以及如何使用它加速访问线性内存与 CUDA 数组（Array）。</p>
<p><em>本文大部分内容来自网络，我做了一些调整，加了一个例子。我经常解决了一个问题之后下次又碰到一样的问题，然后又是一翻搜寻。在那种时候我总是会想：“我当时有写文章就好了”，所以我觉得还是把平日里遇到的小问题、看到的好文章都整理整理总结总结，积少成多，对精进技术应该会有帮助。</em></p>
<h2>纹理存储器（Texture Memory）</h2>
<h3>纹理存储器是什么</h3>
<p>首先明确：纹理存储器是一种只读存储器，由 GPU 用于纹理渲染的图形专用单元发展而来。它同样位于显存中，但是在访问时有许多优秀的特性，例如可通过纹理缓存加速读取。相对同样具有缓存功能的常数存储器（Constant Memory），纹理存储器可以绑定更大的数据，并且支持一维、二维、三维纹理，并可以通过浮点数寻址。由于纹理存储器转为图像纹理渲染而设计，它特别适合图像处理、查找表等，对随机访问与非对齐访问有良好的加速效果，并且可以按需在返回时同时进行滤波等操作。一个很直观的例子，下面的矩阵中 1,2,3,4 四个数据在行优先的线性存储中并不具有相邻的物理地址，因此连续索引这些数据效率是低下的；但是纹理存储可以在读取其中某个数据时将临近的值载入缓存（Cache），这样下次访问时，则可以直接命中缓存，减少对 Global Memory 的访问，从而提高效率。</p>
<p><figure class="pswp-item" style="flex: 50.27075812274368" data-width="557" data-height="554"><img src="https://cdn.jsdelivr.net/gh/AlanDecode/site-Blog@gh-pages/archives/assets/482033fc1e4efd3fbcc0e94674d2f969.png" alt="textures_cuda" /><figcaption>textures_cuda</figcaption></figure></p>
<p>对程序员来说，纹理存储是透明的，程序员无需关心内部实现。</p>
<p>在 CUDA 内核函数（Kernel Code）中访问纹理存储器称作纹理拾取（Texture Fetching），作为纹理存储的特性，纹理拾取与普通的访问某一显存地址的数据有很大不同。纹理拾取时采用的坐标可以不同于数据在存储中的真实地址，二者间的转换通过纹理参照系（Texture Reference）来约定，将显存中的数据与约定的纹理参照系关联的操作称为纹理绑定（Texture Binding）。可以与纹理绑定的数据有两种：显存中的线性内存（Linear Memory）和CUDA数组（Array）。线性内存只能与一维纹理绑定，CUDA 数组则可绑定一维、二维、三维纹理。</p>
<p>关于纹理缓存，它有两个作用。首先纹理缓存中的数据可被复用，当访问的数据已经位于缓存中时，访问该数据将命中缓存，减少对 Global Memory 的访问；其次纹理存储可以将拾取坐标附近的几个像元缓存起来，并可以在拾取时进行插值。</p>
<p>关于纹理缓存需要注意的点：由于纹理缓存是只读的，如果你更改了绑定到纹理缓存的数据，纹理缓存中的数据可能并没有被更新，此时拾取到的可能是错误的数据。因此每次修改原始数据都要重新绑定。对绑定 CUDA 数组时不存在此问题（Device 端 CUDA 数组是只读的），但绑定线性内存则要特别注意。</p>
<h3>纹理拾取（Texture Fetching）</h3>
<p>访问纹理中的数据的过程称作纹理拾取。对绑定线性内存的纹理，拾取纹理的坐标只能是定点型、坐标与内存的真实偏移量（Offset）相同。对绑定 CUDA 数组的纹理，拾取坐标是浮点型，并支持许多特殊功能。</p>
<p><strong>浮点形式寻址：</strong>访问时采用浮点型的坐标对纹理进行寻址，也就是说坐标无需是整数。寻址的方式可以使归一化或者非归一化的。对一个坐标范围是 [0:N]*[0:N] 的纹理，当使用归一化的寻址方式时，每个维度上的坐标被映射到 [0.0:1.0f) 的范围中；使用非归一化寻址时，将被映射到 [0.0:N.0f) 的范围内。当访问的坐标不在一个像元的中心时，根据选择的滤波模式不同，将返回不同的值。</p>
<p><strong>滤波模式：</strong>仅对绑定 CUDA 数组的纹理有效。当使用浮点型的坐标寻址纹理时，将根据设定返回不同类型的值。设定可以有：最邻近取样模式（<strong>这里存疑，因为我自己试了一下似乎也不是最近邻，而是直接对坐标取 floor</strong>）和线性滤波模式，这无需多说。需要注意的是，当开启了线性滤波模式时，要对访问的坐标多加注意，注意不要因为线性插值的原因得到错误的值，例如当要访问原本是 (i,j) 的坐标时可能需要转为 (i+0.5f,j+0.5f)，我在 StackOverflow 上看到对这个特性的讲解（自己翻译了一下）：</p>
<blockquote><p>在图形学中，纹理指的是用于描述一个平面的采样点集。也就是说，纹理中的一个点指的就是这个平面在此处的采样，并不存在大小，这就与像素（Pixel）不同，一个 Pixel 是具有空间大小的。</p>
<p>因此 +0.5f 操作保证寻址的位置正好是真正的整数点对应的位置。</p>
</blockquote>
<p>对于最近邻插值得返回值当然无此限制。</p>
<p><strong>寻址模式：</strong>仅对绑定 CUDA 数组的纹理有效，规定了当寻址的坐标超出允许的寻址范围时的行为。有钳位模式与循环模式两种。钳位模式下，当寻址坐标超出了边界，则钳位到最近边界；循环模式下，则是做求模处理。例如纹理坐标范围 [0,1)，访问 1.25 时，钳位模式返回 0.999……处的值，循环模式返回 0.25 处的值。</p>
<p><strong>类型转换：</strong>当像元中数据是 8 bit 或者 16 bit 时，可对拾取的值进行类型转换，映射到 [0.0f,1.0f] 或者 [-1.0f,1.0f]。</p>
<hr>
<p><strong>若要使用纹理内存，大致分为这么几步：首先在 Host 端声明要绑定的线性内存或者 CUDA 数组；其次设置好纹理参照系；然后将纹理参照系与线性内存或者 CUDA 数组绑定；最后在 Kernel 代码中访问纹理内存即可。</strong></p>
<hr>
<h2>CUDA 数组（Array）</h2>
<p>显存中可以分配的空间有两种：线性内存和 CUDA 数组，都可以与纹理参照系绑定，但是 CUDA 数组对纹理拾取有优化，并且在设备端只能通过纹理拾取访问。</p>
<h3>cudaChannelFormatDesc</h3>
<p>在声明一个 CUDA 数组前，首先要以结构体 <code>cudaChannelFormatDesc</code> 设置 CUDA 数组的数据类型。</p>
<div class="highlight"><pre><span></span><span class="k">struct</span> <span class="n">__device_builtin__</span> <span class="n">cudaChannelFormatDesc</span>
<span class="p">{</span>
    <span class="kt">int</span>                        <span class="n">x</span><span class="p">;</span> <span class="cm">/**&lt; x */</span>
    <span class="kt">int</span>                        <span class="n">y</span><span class="p">;</span> <span class="cm">/**&lt; y */</span>
    <span class="kt">int</span>                        <span class="n">z</span><span class="p">;</span> <span class="cm">/**&lt; z */</span>
    <span class="kt">int</span>                        <span class="n">w</span><span class="p">;</span> <span class="cm">/**&lt; w */</span>
    <span class="k">enum</span> <span class="n">cudaChannelFormatKind</span> <span class="n">f</span><span class="p">;</span> <span class="cm">/**&lt; Channel format kind */</span>
<span class="p">};</span>
</pre></div>
<p>其中，<code>x,y,z,w</code> 表示返回每个成员的位数，<code>cudaChannelFormatKind</code>表示成员类型，这是一个枚举类型，可以取值：</p>
<p><code>cudaChannelFormatKindSigned</code>：有符号整型</p>
<p><code>cudaChannelFormatKindUnsigned</code>：无符号整型</p>
<p><code>cudaChannelFormatKindFloat</code>：浮点型</p>
<p><code>cudaChannelFormatKindNone</code>：无类型</p>
<p><code>cudaChannelFormatDesc</code> 可以用一个简单的函数构造：<code>struct cudaChannelFormatDesc cudaCreateChannelDesc(int x, int y, int z, int w, enum cudaChannelFormatKind f);</code>。在只需要类型信息时，可以使用简化版的：<code>struct cudaChannelFormatDesc cudaCreateChannelDesc&lt;T&gt;();</code>。</p>
<h3>cudaExtent</h3>
<p>然后需要确定 CUDA 数组的纬度与尺寸。纬度与尺寸通过一个结构体 <code>cudaExtent</code> 描述：</p>
<div class="highlight"><pre><span></span><span class="k">struct</span> <span class="n">__device_builtin__</span> <span class="n">cudaExtent</span>
<span class="p">{</span>
    <span class="kt">size_t</span> <span class="n">width</span><span class="p">;</span>     <span class="cm">/**&lt; Width in elements when referring to array memory, in bytes when referring to linear memory */</span>
    <span class="kt">size_t</span> <span class="n">height</span><span class="p">;</span>    <span class="cm">/**&lt; Height in elements */</span>
    <span class="kt">size_t</span> <span class="n">depth</span><span class="p">;</span>     <span class="cm">/**&lt; Depth in elements */</span>
<span class="p">};</span>
</pre></div>
<p>成员分别代表长宽高。可以用一个函数来构造：<code>struct cudaExtent make_cudaExtent(size_t w, size_t h, size_t d)</code>。</p>
<h3>为 CUDA 数组分配空间</h3>
<p>CUDA 数组可通过 <code>cudaMalloc3DArray()</code> 或者 <code>cudaMallocArray()</code> 分配空间。其中， <code>cudaMalloc3DArray()</code> 可分配一维、二维、三维空间，而 <code>cudaMallocArray()</code> 一般用于分配二维数组。使用完数组后，需要使用 <code>cudaFreeArray()</code> 释放空间。</p>
<h3>拷贝数据到 CUDA 数组</h3>
<p>对普通线性内存，使用 <code>cudaMemcpy()</code>，对 CUDA 数组使用 <code>cudaMemcpy2D()</code>、<code>cudaMemcpy3D()</code>。注意这里可能比较 tricky，根据显卡的性能和资源限制，拷贝的大小不能过大。</p>
<h2>纹理参考系（Texture Reference）</h2>
<h3>纹理参考系声明</h3>
<p>纹理参考系中的某些属性需要在编译期确定。texture 类型继承自 textureReference，类似这样构造：<code>texture&lt;T, texType, cudaTextureReadMode&gt; tex;</code>。</p>
<p><code>T</code> 指明由纹理拾取返回的数据类型。可以是基本整形，或者单精度浮点型组成的 1-，2-，4- 元组向量类型。</p>
<p><code>texType</code> 指明了纹理排布方式。取值：<code>cudaTextureType1D</code>、<code>cudaTextureType3D</code>、<code>cudaTextureType3D</code>、<code>cudaTextureType1DLayered</code>、<code>cudaTextureType2DLayered</code>等。</p>
<p><code>cudaTextureReadMode</code> 可取值 <code>cudaReadModeNormalizedFloat</code> 或者 <code>cudaReadModeElementType</code>，本参数可选，缺省 <code>cudaReadModeElementType</code>。当取 <code>cudaReadModeNormalizedFloat</code> 时，若 T 为整型，视 T 是否有符号则将被映射到 [-1.0f,1.0f]或者 [0.0f,1.0f]。 <code>cudaReadModeElementType</code>不对输出转换。</p>
<h3>设置运行时的纹理参考系属性</h3>
<p>除以上需要在编译器确定的属性外，纹理参考系有可在运行时确定的属性：</p>
<div class="highlight"><pre><span></span><span class="k">struct</span> <span class="n">__device_builtin__</span> <span class="n">textureReference</span>
<span class="p">{</span>
    <span class="kt">int</span>                          <span class="n">normalized</span><span class="p">;</span>
    <span class="k">enum</span> <span class="n">cudaTextureFilterMode</span>   <span class="n">filterMode</span><span class="p">;</span>
    <span class="k">enum</span> <span class="n">cudaTextureAddressMode</span>  <span class="n">addressMode</span><span class="p">[</span><span class="mi">3</span><span class="p">];</span>
    <span class="k">struct</span> <span class="n">cudaChannelFormatDesc</span> <span class="n">channelDesc</span><span class="p">;</span>
<span class="p">};</span>
</pre></div>
<p><code>normalized</code>：返回是否归一化，如上文所述。对一个坐标范围是 [0:N]*[0:N] 的纹理，当使用归一化的寻址方式时，每个维度上的坐标被映射到 [0.0:1.0f) 的范围中；使用非归一化寻址时，将被映射到 [0.0:N.0f) 的范围内。</p>
<p><code>filterMode</code>：滤波模式。仅对绑定 CUDA 数组的纹理有效。当使用浮点型的坐标寻址纹理时，将根据设定返回不同类型的值。设定可以有：<code>cudaFilterModePoint</code>和<code>cudaFilterModeLinear</code>。分别表示最近邻插值（<strong>如上文所述，存疑。我觉得好像是直接对浮点坐标做了 floor</strong>）和线性插值。</p>
<p><code>addressMode[3]</code>：寻址模式，即如何处理越界的纹理坐标。可设置：<code>cudaAddressModeClamp</code>和<code>cudaAddressModeWrap</code>。Clamp 即钳位模式，Wrap 为循环模式。循环模式只支持归一化的纹理坐标。</p>
<p><code>channelDesc</code>：描述纹理返回值类型，同 CUDA 数组部分的内容。</p>
<h3>纹理绑定</h3>
<p>使用 <code>cudaBindTextureToArray();</code> 或者 <code>cudaBindTexture();</code> 或者 <code>cudaBindTexture2D();</code>。</p>
<p>取消绑定：<code>cudaUnbindTexture()</code>。</p>
<h3>纹理拾取</h3>
<p>根据不同的纹理类型，采用不同的方式来拾取。与线性内存绑定的纹理，使用<code>texfetch1D()</code>来拾取；对 CUDA 数组，使用 <code>tex1D()</code>、<code>tex2D()</code>、<code>tex3D()</code>来拾取，并使用浮点坐标。</p>
<h2>一个例子</h2>
<p>举个例子，当前有一个 <code>float matrix[3][4]</code> ，将其载入显存，分配为 CUDA 2D 数组，作为纹理使用，并在 kernel code 中拾取。假设当前 matrix 已经初始化完毕。</p>
<h3>代码</h3>
<p>纹理声明：</p>
<div class="highlight"><pre><span></span><span class="n">texture</span><span class="o">&lt;</span><span class="kt">float</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="n">cudaReadModeElementType</span><span class="o">&gt;</span> <span class="n">tex_mat</span><span class="p">;</span>
</pre></div>
<p>Host Code：</p>
<div class="highlight"><pre><span></span><span class="kt">int</span> <span class="nf">main</span><span class="p">()</span>
<span class="p">{</span>
    <span class="p">...</span>

    <span class="n">cudaError</span> <span class="n">err</span><span class="p">;</span>
    <span class="n">cudaArray</span> <span class="o">*</span><span class="n">arr_mat</span><span class="p">;</span>
    <span class="n">cudaChannelFormatDesc</span> <span class="n">channelDesc</span> <span class="o">=</span> <span class="n">cudaCreateChannelDesc</span><span class="o">&lt;</span><span class="kt">float</span><span class="o">&gt;</span><span class="p">();</span>
    <span class="n">cudaMallocArray</span><span class="p">((</span><span class="n">cudaArray</span><span class="o">**</span><span class="p">)</span><span class="o">&amp;</span><span class="n">arr_mat</span><span class="p">,</span><span class="o">&amp;</span><span class="n">channelDesc</span><span class="p">,</span><span class="mi">4</span><span class="p">,</span><span class="mi">3</span><span class="p">);</span>
    <span class="n">err</span> <span class="o">=</span> <span class="n">cudaMemcpyToArray</span><span class="p">(</span><span class="n">arr_mat</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">matrix</span><span class="p">,</span> <span class="mi">3</span> <span class="o">*</span> <span class="mi">4</span><span class="o">*</span><span class="k">sizeof</span><span class="p">(</span><span class="kt">float</span><span class="p">),</span> <span class="n">cudaMemcpyHostToDevice</span><span class="p">);</span>
    <span class="k">if</span> <span class="p">(</span><span class="n">cudaSuccess</span> <span class="o">!=</span> <span class="n">err</span><span class="p">)</span>
        <span class="n">printf</span><span class="p">(</span><span class="s">&quot;CUDA ERROR : %s </span><span class="se">\n</span><span class="s">&quot;</span><span class="p">,</span> <span class="n">cudaGetErrorString</span><span class="p">(</span><span class="n">err</span><span class="p">));</span>

    <span class="n">tex_mat</span><span class="p">.</span><span class="n">normalized</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span>
    <span class="n">tex_mat</span><span class="p">.</span><span class="n">filterMode</span> <span class="o">=</span> <span class="n">cudaFilterModePoint</span><span class="p">;</span>
    <span class="c1">//tex_mat.filterMode = cudaFilterModeLinear;</span>
    <span class="n">tex_mat</span><span class="p">.</span><span class="n">addressMode</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="n">cudaAddressModeClamp</span><span class="p">;</span>
    <span class="n">tex_mat</span><span class="p">.</span><span class="n">addressMode</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">cudaAddressModeClamp</span><span class="p">;</span>
    <span class="n">tex_mat</span><span class="p">.</span><span class="n">addressMode</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span> <span class="o">=</span> <span class="n">cudaAddressModeClamp</span><span class="p">;</span>
    <span class="n">tex_mat</span><span class="p">.</span><span class="n">channelDesc</span> <span class="o">=</span> <span class="n">channelDesc</span><span class="p">;</span>

    <span class="n">err</span> <span class="o">=</span> <span class="n">cudaBindTextureToArray</span><span class="p">(</span><span class="n">tex_mat</span><span class="p">,</span> <span class="p">(</span><span class="n">cudaArray</span><span class="o">*</span><span class="p">)</span><span class="n">arr_mat</span><span class="p">,</span><span class="n">channelDesc</span><span class="p">);</span>
    <span class="k">if</span> <span class="p">(</span><span class="n">cudaSuccess</span> <span class="o">!=</span> <span class="n">err</span><span class="p">)</span>
        <span class="n">printf</span><span class="p">(</span><span class="s">&quot;CUDA ERROR : %s </span><span class="se">\n</span><span class="s">&quot;</span><span class="p">,</span> <span class="n">cudaGetErrorString</span><span class="p">(</span><span class="n">err</span><span class="p">));</span>

    <span class="n">dim3</span> <span class="n">dimBlock</span> <span class="o">=</span> <span class="n">dim3</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">);</span>
    <span class="n">dim3</span> <span class="n">dimGrid</span> <span class="o">=</span> <span class="n">dim3</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">);</span>

    <span class="n">texture_fetching</span> <span class="o">&lt;&lt;&lt;</span><span class="n">dimGrid</span><span class="p">,</span> <span class="n">dimBlock</span> <span class="o">&gt;&gt;&gt;</span> <span class="p">();</span>

    <span class="n">err</span> <span class="o">=</span> <span class="n">cudaUnbindTexture</span><span class="p">(</span><span class="n">tex_mat</span><span class="p">);</span>
    <span class="k">if</span> <span class="p">(</span><span class="n">cudaSuccess</span> <span class="o">!=</span> <span class="n">err</span><span class="p">)</span>
        <span class="n">printf</span><span class="p">(</span><span class="s">&quot;CUDA ERROR : %s </span><span class="se">\n</span><span class="s">&quot;</span><span class="p">,</span> <span class="n">cudaGetErrorString</span><span class="p">(</span><span class="n">err</span><span class="p">));</span>

    <span class="n">err</span> <span class="o">=</span> <span class="n">cudaFreeArray</span><span class="p">(</span><span class="n">arr_mat</span><span class="p">);</span>
    <span class="k">if</span> <span class="p">(</span><span class="n">cudaSuccess</span> <span class="o">!=</span> <span class="n">err</span><span class="p">)</span>
        <span class="n">printf</span><span class="p">(</span><span class="s">&quot;CUDA ERROR : %s </span><span class="se">\n</span><span class="s">&quot;</span><span class="p">,</span> <span class="n">cudaGetErrorString</span><span class="p">(</span><span class="n">err</span><span class="p">));</span>

    <span class="p">...</span>
<span class="p">}</span>
</pre></div>
<p>Kernel Code：</p>
<div class="highlight"><pre><span></span><span class="n">__global__</span>
<span class="kt">void</span> <span class="nf">texture_fetching</span><span class="p">()</span>
<span class="p">{</span>
    <span class="kt">int</span> <span class="n">i</span> <span class="o">=</span> <span class="n">threadIdx</span><span class="p">.</span><span class="n">y</span><span class="p">;</span>
    <span class="kt">int</span> <span class="n">j</span> <span class="o">=</span> <span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="p">;</span>

    <span class="k">if</span> <span class="p">(</span><span class="n">i</span> <span class="o">==</span> <span class="mi">0</span> <span class="o">&amp;&amp;</span> <span class="n">j</span> <span class="o">==</span> <span class="mi">0</span><span class="p">)</span>
    <span class="p">{</span>
        <span class="n">printf</span><span class="p">(</span><span class="s">&quot;Texture Fetch:</span><span class="se">\n</span><span class="s">&quot;</span><span class="p">);</span>
        <span class="k">for</span> <span class="p">(</span><span class="kt">float</span> <span class="n">idxy</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">idxy</span> <span class="o">&lt;</span> <span class="mi">3</span><span class="p">;</span> <span class="n">idxy</span><span class="o">++</span><span class="p">)</span>
        <span class="p">{</span>
            <span class="k">for</span> <span class="p">(</span><span class="kt">float</span> <span class="n">idxx</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">idxx</span> <span class="o">&lt;</span> <span class="mi">4</span><span class="p">;</span> <span class="n">idxx</span><span class="o">++</span><span class="p">)</span>
            <span class="p">{</span>
                <span class="n">printf</span><span class="p">(</span><span class="s">&quot;%f &quot;</span><span class="p">,</span> <span class="n">tex2D</span><span class="p">(</span><span class="n">tex_mat</span><span class="p">,</span> <span class="n">idxx</span><span class="p">,</span> <span class="n">idxy</span><span class="p">));</span>
            <span class="p">}</span>
            <span class="n">printf</span><span class="p">(</span><span class="s">&quot;</span><span class="se">\n</span><span class="s">&quot;</span><span class="p">);</span>
        <span class="p">}</span>
        <span class="n">printf</span><span class="p">(</span><span class="s">&quot;</span><span class="se">\n</span><span class="s">Some other points: </span><span class="se">\n</span><span class="s">&quot;</span><span class="p">);</span>        
        <span class="n">printf</span><span class="p">(</span><span class="s">&quot;tex_mat(0.1,1.0) = %f</span><span class="se">\n</span><span class="s">&quot;</span><span class="p">,</span> <span class="n">tex2D</span><span class="p">(</span><span class="n">tex_mat</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mf">1.</span><span class="p">));</span>
        <span class="n">printf</span><span class="p">(</span><span class="s">&quot;tex_mat(1.4,2.0) = %f</span><span class="se">\n</span><span class="s">&quot;</span><span class="p">,</span> <span class="n">tex2D</span><span class="p">(</span><span class="n">tex_mat</span><span class="p">,</span> <span class="mf">1.4</span><span class="p">,</span> <span class="mf">2.</span><span class="p">));</span>
        <span class="n">printf</span><span class="p">(</span><span class="s">&quot;tex_mat(0.999,2.0) = %f</span><span class="se">\n</span><span class="s">&quot;</span><span class="p">,</span> <span class="n">tex2D</span><span class="p">(</span><span class="n">tex_mat</span><span class="p">,</span> <span class="mf">0.999</span><span class="p">,</span> <span class="mf">2.</span><span class="p">));</span>
        <span class="n">printf</span><span class="p">(</span><span class="s">&quot;tex_mat(1.0,3.5) = %f</span><span class="se">\n</span><span class="s">&quot;</span><span class="p">,</span> <span class="n">tex2D</span><span class="p">(</span><span class="n">tex_mat</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">3.5</span><span class="p">));</span>
    <span class="p">}</span>
<span class="p">}</span>
</pre></div>
<h3>结果</h3>
<p>当 <code>tex_mat.filterMode = cudaFilterModePoint;</code> 时输出：</p>
<p><figure class="pswp-item" style="flex: 78.75751503006012" data-width="786" data-height="499"><img src="https://cdn.jsdelivr.net/gh/AlanDecode/site-Blog@gh-pages/archives/assets/fb9a09bc92ec21f669024318c3b6779b.png" alt="filtpoint" /><figcaption>filtpoint</figcaption></figure></p>
<p>当 <code>tex_mat.filterMode = cudaFilterModeLinear;</code> 时输出：</p>
<p><figure class="pswp-item" style="flex: 71.93158953722335" data-width="715" data-height="497"><img src="https://cdn.jsdelivr.net/gh/AlanDecode/site-Blog@gh-pages/archives/assets/b9df65c6b89a806ea5cfc821f99b153a.png" alt="filtlinear" /><figcaption>filtlinear</figcaption></figure></p>

            </div>
        </article>
        <div id="ga-tags">
    
</div>
    </section>

    
<section id="ga-content_pager">

    <div class="next">
        <a class="ga-highlight" href="/archives/107/">一种使用 CMake 实现 C/C++ 与 CUDA 混合编译的方法</a>
        <p class="yue">原理是把 CUDA 代码编译为静态库，然后链接到 Host 代码上。</p>
    </div>


    <div class="prev">
        <a class="ga-highlight" href="/archives/103/">《千年女优》：像我这样寻找的人</a>
        <p class="yue">《千年女优》整部电影里面真实与幻境交替，主角作为寻常女子和作为所扮演的角色身份混杂在一起，从不同角度不同时间不同空间来刻画女主一生的追寻。电影的实验性质很强烈，从配乐上就能感受出来：这无论怎样都不是当谈起“刻画二战时一位女演员的爱情故事的电影”时我会构想出的音乐。</p>
    </div>

</section>


    
        <script>
            var initValine = function () {
                new Valine({"enable": true, "el": "#vcomments", "appId": "6chFXPTjrjYnjFk9duROcboN-gzGzoHsz", "appKey": "c1CRooaFmpLs4xi7x3YLm3ma", "visitor": true, "recordIP": true, "placeholder": "\u6765\u7545\u6240\u6b32\u8a00\u5427~"});
            }
        </script>
        <script defer src='https://cdn.jsdelivr.net/npm/valine@1.3.10/dist/Valine.min.js' onload="initValine()"></script>
        <div id="vcomments"></div>
    

</main>

                <footer class="ga-mono" id="ga-footer">
                    <section>
                        <span id="ga-uptime"></span>
                        <span class="brand">无文字 | 三无计划</span>
                    </section>
                    <section>
                        <p class="copyright">
                            <span>Copyright © 2020 熊猫小A</span>
                            <span>Powered by <a no-style href="https://github.com/AlanDecode/Maverick" target="_blank">Maverick & Galileo</a></span>
                        </p>
                        <div class="copyright">
                            <span class="footer-addon">
                                
<a no-style href="http://beian.miit.gov.cn" target="_blank">京ICP备18000133号-1</a> | 
<a no-style href="https://www.upyun.com" target="_blank">又拍云</a>

                            </span>
                            <nav class="social-links">
                                <ul><li><a class="no-style" title="Twitter" href="https://twitter.com/AlanDecode" target="_blank"><i class="gi gi-twitter"></i>Twitter</a></li><span class="separator">·</span><li><a class="no-style" title="GitHub" href="https://github.com/AlanDecode" target="_blank"><i class="gi gi-github"></i>GitHub</a></li><span class="separator">·</span><li><a class="no-style" title="Weibo" href="https://weibo.com/5245109677/" target="_blank"><i class="gi gi-weibo"></i>Weibo</a></li></ul>
                            </nav>
                        </div>
                    </section>
                    <script>
                        var site_build_date = "2017-06-29T12:00+08:00"
                    </script>
                    <script src="https://cdn.jsdelivr.net/gh/AlanDecode/site-Blog@gh-pages/assets/galileo-0502e826c1.js"></script>
                </footer>
            </div>
        </div>
    </div>
        
        
        <div class="pswp" tabindex="-1" role="dialog" aria-hidden="true">
        <div class="pswp__bg"></div>
        <div class="pswp__scroll-wrap">
            <div class="pswp__container">
                <div class="pswp__item"></div>
                <div class="pswp__item"></div>
                <div class="pswp__item"></div>
            </div>
            <div class="pswp__ui pswp__ui--hidden">
                <div class="pswp__top-bar">
                    <div class="pswp__counter"></div>
                    <button class="pswp__button pswp__button--close" title="Close (Esc)"></button>
                    <button class="pswp__button pswp__button--share" title="Share"></button>
                    <button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>
                    <button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button>
                    <div class="pswp__preloader">
                        <div class="pswp__preloader__icn">
                          <div class="pswp__preloader__cut">
                            <div class="pswp__preloader__donut"></div>
                          </div>
                        </div>
                    </div>
                </div>
                <div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap">
                    <div class="pswp__share-tooltip"></div> 
                </div>
                <button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
                </button>
                <button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)">
                </button>
                <div class="pswp__caption">
                    <div class="pswp__caption__center"></div>
                </div>
            </div>
        </div>
    </div>

    <script src="https://cdn.jsdelivr.net/gh/AlanDecode/site-Blog@gh-pages/assets/ExSearch/jquery.min.js"></script>
    <script src="https://cdn.jsdelivr.net/gh/AlanDecode/site-Blog@gh-pages/assets/ExSearch/ExSearch-493cb9cd89.js"></script>
    
    <!--katex-->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/AlanDecode/site-Blog@gh-pages/assets/katex.min.css">
    <script defer src="https://cdn.jsdelivr.net/gh/AlanDecode/site-Blog@gh-pages/assets/katex.min.js"></script>
    <script>
    mathOpts = {
        delimiters: [
            {left: "$$", right: "$$", display: true},
            {left: "\\[", right: "\\]", display: true},
            {left: "$", right: "$", display: false},
            {left: "\\(", right: "\\)", display: false}
        ]
    };
    </script>
    <script defer src="https://cdn.jsdelivr.net/gh/AlanDecode/site-Blog@gh-pages/assets/auto-render.min.js" onload="renderMathInElement(document.body, mathOpts);"></script>

    
<script>
    var _hmt = _hmt || [];
    (function() {
    var hm = document.createElement("script");
    hm.src = "https://hm.baidu.com/hm.js?e4f3a7c02ac2aabc41a1cfa95f61a026";
    var s = document.getElementsByTagName("script")[0]; 
    s.parentNode.insertBefore(hm, s);
    })();
</script>
<script>
    (function(){
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        }
        else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>
<script>
if(window.location.hash){
    var checkExist = setInterval(function() {
       if ($(window.location.hash).length) {
          $('html, body').animate({scrollTop: $(window.location.hash).offset().top-90}, 1000);
          clearInterval(checkExist);
       }
    }, 100);
}
</script>
<script>
if(window.navigator && navigator.serviceWorker) {
  caches.keys().then(function(cacheNames) {
    cacheNames.forEach(function(cacheName) {
      caches.delete(cacheName);
    });
  }).then(function(){
    console.log('Cache cleaned.');
  });
  navigator.serviceWorker.getRegistrations()
  .then(function(registrations) {
    for(let registration of registrations) {
      registration.unregister();
    }
  }).then(function(){
    console.log('Service Worker stopped.');
  });
}
</script>

    </body>
</html>